{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "aea74416",
      "metadata": {},
      "source": [
        "# Time-course hierarchical clustering (first-pass metrics)\n",
        "\n",
        "This notebook reproduces the PNG + Excel + ZIP outputs we generated in chat.\n",
        "\n",
        "**You only need to edit the `INPUT_PATH`, `OUTPUT_DIR`, and `DROP_TIMEPOINTS` variables in the next cell.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c583bc8a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ====== USER SETTINGS (edit these) ======\n",
        "INPUT_PATH = r\"J:/Cohen Lab/Maria Clara/2_Lab data/9_Napari/OUTPUT new code/New PCA soma/PCA cleaning/Data S1.csv\"  # CSV or XLSX\n",
        "OUTPUT_DIR = r\"J:/Cohen Lab/Maria Clara/2_Lab data/9_Napari/OUTPUT new code/hierarchical clustering/OUT_timecourse_clustering/OUT_timecourse_k12_DiffLayout\"  # folder will be overwritten\n",
        "\n",
        "# Put timepoints to drop here. Examples:\n",
        "#   []            -> keep all\n",
        "#   [\"iPSCs\"]     -> neurites-style\n",
        "DROP_TIMEPOINTS = []\n",
        "\n",
        "# Clustering + plotting parameters\n",
        "TP_ORDER = [\"iPSCs\", \"day7\", \"day14\", \"day21\", \"day28\"]\n",
        "KMAX = 12\n",
        "MIN_NON_NA = 5\n",
        "VLIM = 2.5\n",
        "DPI = 170\n",
        "CMAP = \"BrBG\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d59d3994",
      "metadata": {},
      "outputs": [],
      "source": [
        "import re, shutil, warnings\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
        "from scipy.spatial.distance import pdist\n",
        "\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "817cfd3c",
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize_tp(x):\n",
        "    if pd.isna(x):\n",
        "        return None\n",
        "    s = str(x).lower()\n",
        "    if \"ipsc\" in s:\n",
        "        return \"iPSCs\"\n",
        "    for d in [28, 21, 14, 7]:\n",
        "        if re.search(rf\"day[\\s_-]*{d}\\b\", s):\n",
        "            return f\"day{d}\"\n",
        "    for d in [28, 21, 14, 7]:\n",
        "        if re.search(rf\"(?<!\\d)d[\\s_-]*{d}(?!\\d)\", s):\n",
        "            return f\"day{d}\"\n",
        "    return None\n",
        "\n",
        "def find_tp_col(df):\n",
        "    for c in df.columns:\n",
        "        if c.lower().replace('_','-') in ['cell-type','celltype','cell_type']:\n",
        "            return c\n",
        "    for c in df.columns[:30]:\n",
        "        if df[c].astype(str).str.contains('day|ipsc|d7|d14|d21|d28', case=False, na=False).mean() > 0.2:\n",
        "            return c\n",
        "    raise ValueError(\"Couldn't find timepoint column. Expected something like 'cell-type'.\")\n",
        "\n",
        "def find_image_col(df):\n",
        "    for c in df.columns:\n",
        "        if c.lower().replace('_','-') in ['image-name','imagename','image_name']:\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "def ensure_numeric(df, cols, min_non_na):\n",
        "    keep = []\n",
        "    for c in cols:\n",
        "        if pd.api.types.is_numeric_dtype(df[c]):\n",
        "            keep.append(c)\n",
        "        else:\n",
        "            coer = pd.to_numeric(df[c], errors='coerce')\n",
        "            if coer.notna().sum() >= min_non_na:\n",
        "                df[c] = coer\n",
        "                keep.append(c)\n",
        "    return keep\n",
        "\n",
        "def plot_heat(out_png, Z, labels_ord, matrix, tp_order, vlim, cmap,\n",
        "              percell_mode=False, tp_idx_vec=None, dpi=170):\n",
        "    \"\"\"Timecourse heatmap with:\n",
        "      - dendrogram on the LEFT\n",
        "      - a vertical cluster-color strip between dendrogram and heatmap\n",
        "      - a clean legend for clusters (no overlaps)\n",
        "      - timepoint labels ABOVE the heatmap\n",
        "      - horizontal z-score colorbar BELOW\n",
        "    \"\"\"\n",
        "    import seaborn as sns\n",
        "    import matplotlib.patches as mpatches\n",
        "\n",
        "    fig = plt.figure(figsize=(16, 22))\n",
        "\n",
        "    # Axes layout (figure coords):\n",
        "    # dendrogram (left), cluster strip (thin), heatmap (center), colorbar (bottom under heatmap)\n",
        "    ax_d = fig.add_axes([0.05, 0.12, 0.18, 0.78])   # dendrogram (left)\n",
        "    ax_s = fig.add_axes([0.235, 0.12, 0.015, 0.78]) # cluster strip\n",
        "    ax_h = fig.add_axes([0.255, 0.12, 0.69, 0.78])  # heatmap\n",
        "    ax_c = fig.add_axes([0.255, 0.06, 0.69, 0.02])  # colorbar (below heatmap)\n",
        "\n",
        "    # --- Dendrogram on the left, pointing RIGHT toward the heatmap\n",
        "    if Z is not None and matrix.shape[0] > 1:\n",
        "        dendrogram(Z, orientation='left', ax=ax_d, no_labels=True, color_threshold=None)\n",
        "    ax_d.set_xticks([]); ax_d.set_yticks([])\n",
        "\n",
        "    # --- Cluster strip colors (based on labels_ord, which already matches the plotted order)\n",
        "    clusters = sorted(np.unique(labels_ord))\n",
        "    pal = sns.color_palette(\"tab20\", n_colors=len(clusters))\n",
        "    cl2color = {cl: pal[i] for i, cl in enumerate(clusters)}\n",
        "    strip_rgb = np.array([cl2color[int(cl)] for cl in labels_ord]).reshape(-1, 1, 3)\n",
        "\n",
        "    ax_s.imshow(strip_rgb, aspect='auto', interpolation='nearest')\n",
        "    ax_s.set_xticks([]); ax_s.set_yticks([])\n",
        "\n",
        "    # --- Heatmap\n",
        "    im = ax_h.imshow(matrix, aspect='auto', interpolation='nearest', cmap=cmap, vmin=-vlim, vmax=vlim)\n",
        "    ax_h.set_yticks([])\n",
        "\n",
        "    # Put timepoint labels ABOVE the heatmap\n",
        "    ax_h.xaxis.set_ticks_position('top')\n",
        "    ax_h.xaxis.set_label_position('top')\n",
        "    ax_h.tick_params(axis='x', top=True, bottom=False, labeltop=True, labelbottom=False)\n",
        "\n",
        "    if percell_mode and tp_idx_vec is not None:\n",
        "        x_pos, labs = [], []\n",
        "        for tp in sorted(np.unique(tp_idx_vec)):\n",
        "            idxs = np.where(tp_idx_vec == tp)[0]\n",
        "            if len(idxs) == 0:\n",
        "                continue\n",
        "            if len(x_pos) > 0:\n",
        "                ax_h.axvline(idxs[0] - 0.5, color='black', lw=0.5)\n",
        "            x_pos.append(int((idxs[0] + idxs[-1]) / 2))\n",
        "            labs.append(tp_order[tp])\n",
        "        ax_h.set_xticks(x_pos); ax_h.set_xticklabels(labs, fontsize=9)\n",
        "        ax_h.set_xlabel('Cells grouped by time point')\n",
        "    else:\n",
        "        ax_h.set_xticks(range(len(tp_order)))\n",
        "        ax_h.set_xticklabels(tp_order, fontsize=10)\n",
        "        ax_h.set_xlabel('Time point (median z)')\n",
        "\n",
        "    # --- Horizontal colorbar BELOW\n",
        "    cb = plt.colorbar(im, cax=ax_c, orientation='horizontal')\n",
        "    cb.set_label('z-score')\n",
        "\n",
        "    # --- Cluster legend (top-left, away from dendrogram)\n",
        "    handles = [mpatches.Patch(color=cl2color[int(cl)], label=f\"Cluster {int(cl)}\") for cl in clusters]\n",
        "    fig.legend(handles=handles, title=\"Metric clusters\", loc=\"upper left\",\n",
        "               bbox_to_anchor=(0.255, 1.15), frameon=True, ncol=1)\n",
        "\n",
        "    fig.savefig(out_png, dpi=dpi, bbox_inches='tight', pad_inches=0.2)\n",
        "    plt.close(fig)\n",
        "\n",
        "def write_excel(path, overview_dict, metrics_flat, med_flat, tp_order,\n",
        "                metrics_ord, labels_ord, med_ord, z_ord, dz_ord):\n",
        "    with pd.ExcelWriter(path, engine=\"openpyxl\") as xw:\n",
        "        pd.DataFrame({'item': list(overview_dict.keys()), 'value': list(overview_dict.values())}).to_excel(\n",
        "            xw, 'overview', index=False\n",
        "        )\n",
        "        pd.DataFrame({'flat_metric': metrics_flat}).to_excel(xw, 'flat_metrics_list', index=False)\n",
        "        if len(metrics_flat):\n",
        "            pd.DataFrame(med_flat, index=metrics_flat,\n",
        "                         columns=[f'median_{tp}' for tp in tp_order]).to_excel(\n",
        "                xw, 'flat_medians_byTP', index=True\n",
        "            )\n",
        "\n",
        "        master = pd.DataFrame({'metric': metrics_ord, 'cluster_id': labels_ord})\n",
        "        for i, tp in enumerate(tp_order):\n",
        "            master[f'median_{tp}'] = med_ord[:, i]\n",
        "            master[f'z_{tp}'] = z_ord[:, i]\n",
        "        for i, (a, b) in enumerate(zip(tp_order[:-1], tp_order[1:])):\n",
        "            master[f'dz_{b}-vs-{a}'] = dz_ord[:, i]\n",
        "        master['sum_abs_dz'] = np.abs(dz_ord).sum(axis=1)\n",
        "        master['rank_sum_abs_dz'] = master['sum_abs_dz'].rank(ascending=False, method='dense').astype(int)\n",
        "        master.to_excel(xw, 'metric_to_cluster', index=False)\n",
        "\n",
        "        for cid in sorted(pd.unique(labels_ord)):\n",
        "            tab = master[master['cluster_id'] == cid].sort_values('rank_sum_abs_dz')\n",
        "            tab.to_excel(xw, f'c{cid}'[:31], index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "575c2ac8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded rows: 395\n",
            "Timepoint column used: cell_type\n",
            "Image column: image_name\n",
            "Timepoints used: ['iPSCs', 'day7', 'day14', 'day21', 'day28']\n",
            "Metrics (>= MIN_NON_NA): 248\n",
            "Dynamic metrics: 190 | Flat metrics: 58\n"
          ]
        }
      ],
      "source": [
        "# ====== RUN PIPELINE ======\n",
        "inp = Path(INPUT_PATH)\n",
        "outdir = Path(OUTPUT_DIR)\n",
        "if outdir.exists():\n",
        "    shutil.rmtree(outdir)\n",
        "outdir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Load\n",
        "if inp.suffix.lower() in ['.xlsx', '.xls']:\n",
        "    xl = pd.ExcelFile(inp)\n",
        "    df0 = xl.parse(xl.sheet_names[0])\n",
        "else:\n",
        "    df0 = pd.read_csv(inp)\n",
        "\n",
        "df0.columns = [str(c) for c in df0.columns]\n",
        "tp_col = find_tp_col(df0)\n",
        "img_col = find_image_col(df0)\n",
        "\n",
        "df0['dataset_norm'] = df0[tp_col].apply(normalize_tp)\n",
        "\n",
        "# Apply DROP\n",
        "drop_set = set(DROP_TIMEPOINTS or [])\n",
        "df = df0[df0['dataset_norm'].isin(TP_ORDER)].copy()\n",
        "if drop_set:\n",
        "    df = df[~df['dataset_norm'].isin(drop_set)].copy()\n",
        "\n",
        "tp_order_use = [tp for tp in TP_ORDER if tp not in drop_set]\n",
        "assert len(tp_order_use) >= 2, 'Need at least 2 timepoints after DROP.'\n",
        "\n",
        "tp_to_idx = {tp:i for i,tp in enumerate(tp_order_use)}\n",
        "df['_tp_idx'] = df['dataset_norm'].map(tp_to_idx).astype(int)\n",
        "df = df.sort_values('_tp_idx').reset_index(drop=True)\n",
        "\n",
        "# Metrics: all numeric columns except ID columns\n",
        "id_like = {'dataset_norm', '_tp_idx', tp_col}\n",
        "if img_col:\n",
        "    id_like.add(img_col)\n",
        "cand_cols = [c for c in df.columns if c not in id_like]\n",
        "metrics = ensure_numeric(df, cand_cols, MIN_NON_NA)\n",
        "cov = df[metrics].notna().sum(axis=0)\n",
        "metrics_cov = cov[cov >= MIN_NON_NA].index.tolist()\n",
        "\n",
        "# Median per timepoint (forced rows)\n",
        "med_df = df.groupby('_tp_idx')[metrics_cov].median(numeric_only=True).reindex(range(len(tp_order_use)))\n",
        "med = med_df.to_numpy().T\n",
        "\n",
        "# Drop all-NaN metrics\n",
        "ok_any = np.isfinite(med).any(axis=1)\n",
        "metrics2 = [m for m,ok in zip(metrics_cov, ok_any) if ok]\n",
        "med = med[ok_any,:]\n",
        "\n",
        "# Dynamic vs flat\n",
        "var_time = np.nanvar(med, axis=1)\n",
        "mask_dyn = var_time > 0\n",
        "metrics_dyn = [m for m,ok in zip(metrics2, mask_dyn) if ok]\n",
        "metrics_flat = [m for m,ok in zip(metrics2, mask_dyn) if not ok]\n",
        "med_dyn = med[mask_dyn,:]\n",
        "med_flat = med[~mask_dyn,:] if len(metrics_flat) else np.zeros((0,len(tp_order_use)))\n",
        "\n",
        "# z-score across timepoints (median-based)\n",
        "mu = np.nanmean(med_dyn, axis=1, keepdims=True)\n",
        "sd = np.nanstd(med_dyn, axis=1, ddof=1, keepdims=True)\n",
        "sd[~np.isfinite(sd)] = 1.0\n",
        "sd[sd==0] = 1.0\n",
        "z_med = np.nan_to_num((med_dyn-mu)/sd, nan=0.0)\n",
        "dz = z_med[:,1:] - z_med[:,:-1]\n",
        "\n",
        "# per-cell z-score for visualization\n",
        "tp_idx_vec = df['_tp_idx'].to_numpy()\n",
        "percell = []\n",
        "for m in metrics_dyn:\n",
        "    v = df[m].to_numpy(float)\n",
        "    mu1 = np.nanmean(v)\n",
        "    sd1 = np.nanstd(v, ddof=1)\n",
        "    if not np.isfinite(sd1) or sd1==0:\n",
        "        sd1 = 1.0\n",
        "    percell.append(np.nan_to_num((v-mu1)/sd1, nan=0.0))\n",
        "percell = np.vstack(percell) if percell else np.zeros((0,len(df)))\n",
        "\n",
        "print('Loaded rows:', len(df))\n",
        "print('Timepoint column used:', tp_col)\n",
        "print('Image column:', img_col)\n",
        "print('Timepoints used:', tp_order_use)\n",
        "print('Metrics (>= MIN_NON_NA):', len(metrics_cov))\n",
        "print('Dynamic metrics:', len(metrics_dyn), '| Flat metrics:', len(metrics_flat))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "89ed57f5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ZIP: J:\\Cohen Lab\\Maria Clara\\2_Lab data\\9_Napari\\OUTPUT new code\\hierarchical clustering\\OUT_timecourse_clustering\\OUT_timecourse_k12_DiffLayout.zip\n"
          ]
        }
      ],
      "source": [
        "# ====== CLUSTER + EXPORT ======\n",
        "def run_diffward():\n",
        "    n = dz.shape[0]\n",
        "    if n <= 1:\n",
        "        return None, list(range(n)), np.ones(n,int)\n",
        "    Z = linkage(pdist(dz, metric='euclidean'), method='ward', optimal_ordering=False)\n",
        "    leaves = dendrogram(Z, no_plot=True)['leaves']\n",
        "    labels = fcluster(Z, t=KMAX, criterion='maxclust')\n",
        "    return Z, leaves, labels\n",
        "\n",
        "def run_corravg():\n",
        "    n = z_med.shape[0]\n",
        "    if n <= 1:\n",
        "        return None, list(range(n)), np.ones(n,int)\n",
        "    corr = np.corrcoef(z_med)\n",
        "    dist = np.nan_to_num(1-corr, nan=1.0)\n",
        "    dcond = dist[np.triu_indices(n,1)]\n",
        "    Z = linkage(dcond, method='average', optimal_ordering=False)\n",
        "    leaves = dendrogram(Z, no_plot=True)['leaves']\n",
        "    labels = fcluster(Z, t=KMAX, criterion='maxclust')\n",
        "    return Z, leaves, labels\n",
        "\n",
        "def run_patterncomplete():\n",
        "    sgn = np.zeros_like(dz, int)\n",
        "    sgn[dz>0] = 1\n",
        "    sgn[dz<0] = -1\n",
        "    n = sgn.shape[0]\n",
        "    if n <= 1:\n",
        "        return None, list(range(n)), np.ones(n,int)\n",
        "    d=[]\n",
        "    for i in range(n-1):\n",
        "        for j in range(i+1,n):\n",
        "            d.append(np.mean(sgn[i,:] != sgn[j,:]))\n",
        "    Z = linkage(np.array(d,float), method='complete', optimal_ordering=False)\n",
        "    leaves = dendrogram(Z, no_plot=True)['leaves']\n",
        "    labels = fcluster(Z, t=KMAX, criterion='maxclust')\n",
        "    return Z, leaves, labels\n",
        "\n",
        "methods = {\n",
        "    'DIFF_WARD': run_diffward,\n",
        "    'CORR_AVG': run_corravg,\n",
        "    'PATTERN_COMPLETE': run_patterncomplete,\n",
        "}\n",
        "\n",
        "meta_rows=[]\n",
        "for name, fn in methods.items():\n",
        "    Z, leaves, labels = fn()\n",
        "    # --- Make cluster IDs match the visual order (top-to-bottom in the dendrogram) ---\n",
        "    # fcluster() assigns numeric labels based on tree traversal, which can look \"scrambled\" compared\n",
        "    # to the dendrogram leaf order. We remap cluster IDs by the order of first appearance in the\n",
        "    # dendrogram-ordered labels, so PNG labels and Excel labels are identical.\n",
        "    def _remap_labels_by_first_appearance(labels_in_leaf_order):\n",
        "        mapping = {}\n",
        "        new = np.empty_like(labels_in_leaf_order, dtype=int)\n",
        "        nxt = 1\n",
        "        for i, old in enumerate(labels_in_leaf_order):\n",
        "            old = int(old)\n",
        "            if old not in mapping:\n",
        "                mapping[old] = nxt\n",
        "                nxt += 1\n",
        "            new[i] = mapping[old]\n",
        "        return new, mapping\n",
        "\n",
        "    metrics_ord = np.array([metrics_dyn[i] for i in leaves])\n",
        "    labels_leaf = labels[leaves]\n",
        "    labels_ord, _label_map = _remap_labels_by_first_appearance(labels_leaf)\n",
        "    # also remap the full label vector (for summary counts etc.)\n",
        "    labels = np.array([_label_map[int(x)] for x in labels], dtype=int)\n",
        "    z_ord = z_med[leaves,:]\n",
        "    dz_ord = dz[leaves,:]\n",
        "    med_ord = med_dyn[leaves,:]\n",
        "    percell_ord = percell[leaves,:]\n",
        "\n",
        "    plot_heat(outdir/f\"{name}_MEDIAN_HEAT_WITH_DENDRO_NUM.png\", Z, labels_ord, z_ord,\n",
        "              tp_order_use, VLIM, CMAP, percell_mode=False, dpi=DPI)\n",
        "    plot_heat(outdir/f\"{name}_PERCELL_HEAT_WITH_DENDRO_NUM.png\", Z, labels_ord, percell_ord,\n",
        "              tp_order_use, VLIM, CMAP, percell_mode=True, tp_idx_vec=tp_idx_vec, dpi=DPI)\n",
        "\n",
        "    overview = {\n",
        "        'input_file': inp.name,\n",
        "        'tp_col_used': tp_col,\n",
        "        'image_col': img_col,\n",
        "        'rows_used': len(df),\n",
        "        f'metrics_cov>={MIN_NON_NA}': len(metrics_cov),\n",
        "        'dynamic_metrics': len(metrics_dyn),\n",
        "        'flat_metrics': len(metrics_flat),\n",
        "        'kmax': KMAX,\n",
        "        'n_clusters': int(pd.Series(labels).nunique()),\n",
        "        'timepoints_present': ', '.join(tp_order_use),\n",
        "        'dropped_timepoints': ', '.join(DROP_TIMEPOINTS) if DROP_TIMEPOINTS else '',\n",
        "    }\n",
        "\n",
        "    write_excel(outdir/f\"{name}_clusters_RAW_andZ.xlsx\", overview,\n",
        "                metrics_flat, med_flat, tp_order_use,\n",
        "                metrics_ord, labels_ord, med_ord, z_ord, dz_ord)\n",
        "\n",
        "    meta_rows.append({'method': name, 'n_clusters': overview['n_clusters']})\n",
        "\n",
        "# Summary CSVs\n",
        "tp_counts = df['dataset_norm'].value_counts().reindex(tp_order_use).fillna(0).astype(int)\n",
        "pd.DataFrame({'dataset': tp_order_use, 'n_cells': tp_counts.values}).to_csv(outdir/'tp_counts.csv', index=False)\n",
        "pd.DataFrame(meta_rows).to_csv(outdir/'cluster_counts.csv', index=False)\n",
        "\n",
        "# Zip\n",
        "zip_path = shutil.make_archive(str(outdir), 'zip', str(outdir))\n",
        "print('ZIP:', zip_path)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
